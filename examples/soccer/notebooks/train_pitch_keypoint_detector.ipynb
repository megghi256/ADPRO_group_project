{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe9vkEvFABbN"
      },
      "source": [
        "[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "# Train Soccer Pitch Keypoint Detector\n",
        "\n",
        "---\n",
        "\n",
        "[![Download Dataset](https://app.roboflow.com/images/download-dataset-badge.svg)](https://universe.roboflow.com/roboflow-jvuqo/football-field-detection-f07vi)\n",
        "\n",
        "This notebook is based on the [How to Train a YOLOv8 Keypint Detection Model](https://github.com/roboflow/notebooks/blob/main/notebooks/train-yolov8-keypoint.ipynb) notebook from the [roboflow/notebooks](https://github.com/roboflow/notebooks) repository."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure API keys\n",
        "\n",
        "- Open your [`Roboflow Settings`](https://app.roboflow.com/settings/api) page. Click `Copy`. This will place your private key in the clipboard.\n",
        "- In Colab, go to the left pane and click on `Secrets` (ğŸ”‘). Store Roboflow API Key under the name `ROBOFLOW_API_KEY`."
      ],
      "metadata": {
        "id": "2Dz1ntWK6n2v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "7fde7f0e-3b2a-4e22-8f46-6f0d9b7596c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "58ba51f4-ce82-4580-fae6-238dc4ef0fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "a233a604-a42d-432c-ffaf-1f7879dc840c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.5/1.0 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/85.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "DEJCraztXlUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "from google.colab import userdata\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "l0hM1TJeXoMl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pull dataset"
      ],
      "metadata": {
        "id": "PaZWb5Y_YCgx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSd93ZJzZZKt",
        "outputId": "a53b8804-c929-45da-9c79-62c412004ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in football-field-detection-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1872/1872 [00:01<00:00, 1690.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to football-field-detection-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 4368.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "rf = Roboflow(api_key=\"BcCi5HI587O02q1v831w\")\n",
        "project = rf.workspace(\"margherita-3vose\").project(\"football-field-detection-f07vi-nqkbw\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** Update `data.yaml` structure to align with the latest requirements of the `ultralytics` package."
      ],
      "metadata": {
        "id": "pU_Lyy0_aNQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's|\\(train: \\).*|\\1../train/images|' {dataset.location}/data.yaml\n",
        "!sed -i 's|\\(val: \\).*|\\1../valid/images|' {dataset.location}/data.yaml"
      ],
      "metadata": {
        "id": "YTXlsdgtbZW4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 1: fine-tune head only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!yolo task=pose mode=train \\\n",
        "    model=/content/drive/MyDrive/TestTesi/video/football-pitch-detection.pt \\\n",
        "    data={dataset.location}/data.yaml \\\n",
        "    batch=8 \\\n",
        "    epochs=20 \\\n",
        "    imgsz=640 \\\n",
        "    freeze=backbone \\\n",
        "    mosaic=0.0 \\\n",
        "    patience=5 \\\n",
        "    lr0=1e-4 \\\n",
        "    plots=True\n",
        "\n"
      ],
      "metadata": {
        "id": "v2IV8D6Cko5n",
        "outputId": "814f2aa1-0839-4b97-89a7-d31354c3601b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Ultralytics 8.3.130 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CPU (AMD EPYC 7B12)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/datasets/football-field-detection-1/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=backbone, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/TestTesi/video/football-pitch-detection.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/pose/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=pose, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1  10379251  ultralytics.nn.modules.head.Pose             [1, [32, 3], [320, 640, 640]] \n",
            "YOLOv8x-pose summary: 224 layers, 69,813,891 parameters, 69,813,875 gradients, 265.4 GFLOPs\n",
            "\n",
            "Transferred 637/637 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2022.3Â±712.1 MB/s, size: 46.3 KB)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/football-field-detection-1/train/labels.cache... 32 images, 0 backgrounds, 0 corrupt: 100% 32/32 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1590.0Â±629.5 MB/s, size: 45.1 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/football-field-detection-1/valid/labels.cache... 2 images, 0 backgrounds, 0 corrupt: 100% 2/2 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/pose/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 103 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/pose/train2\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/20         0G     0.6425      5.923     0.3585      0.507      1.955          8        640: 100% 4/4 [01:56<00:00, 29.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.48s/it]\n",
            "                   all          2          2          1      0.998      0.995      0.895          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/20         0G     0.5828      5.878     0.3008     0.4186      1.794          8        640: 100% 4/4 [01:46<00:00, 26.64s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.25s/it]\n",
            "                   all          2          2      0.985          1      0.995      0.895          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/20         0G     0.4115      5.528     0.2668     0.2804      1.411          8        640: 100% 4/4 [01:46<00:00, 26.72s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.25s/it]\n",
            "                   all          2          2      0.984          1      0.995      0.929          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/20         0G     0.3866      5.981     0.3103     0.3214      1.336          8        640: 100% 4/4 [01:46<00:00, 26.50s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.47s/it]\n",
            "                   all          2          2      0.982          1      0.995      0.895          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/20         0G     0.3514      4.957     0.2316     0.2027      1.348          8        640: 100% 4/4 [01:49<00:00, 27.31s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.28s/it]\n",
            "                   all          2          2          1          1      0.995      0.895          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/20         0G      0.393      4.645     0.2638     0.2799      1.199          8        640: 100% 4/4 [01:47<00:00, 26.76s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.45s/it]\n",
            "                   all          2          2      0.982          1      0.995      0.895          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/20         0G     0.3734      5.534     0.2241     0.2264      1.232          8        640:  50% 2/4 [01:20<01:20, 40.49s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/__init__.py\", line 981, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 793, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\", line 212, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\", line 395, in _do_train\n",
            "    self.scaler.scale(self.loss).backward()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 2: unfreeze and refine â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!yolo task=pose mode=train \\\n",
        "    model=runs/train/your_soccer_pitch_pretrained/weights/best.pt \\\n",
        "    data={dataset.location}/data.yaml \\\n",
        "    batch=8 \\\n",
        "    epochs=80 \\\n",
        "    imgsz=640 \\\n",
        "    freeze=0 \\\n",
        "    mosaic=0.0 \\\n",
        "    patience=5 \\\n",
        "    lr0=5e-5 \\\n",
        "    plots=True\n"
      ],
      "metadata": {
        "id": "nG2lM5lhkqSQ",
        "outputId": "c49a46d8-e44b-40d3-a019-3132ef39302a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/__init__.py\", line 952, in entrypoint\n",
            "    model = YOLO(model, task=task)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/model.py\", line 53, in __init__\n",
            "    super().__init__(model=model, task=task, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 148, in __init__\n",
            "    self._load(model, task=task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 292, in _load\n",
            "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\", line 1306, in attempt_load_one_weight\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\", line 1211, in torch_safe_load\n",
            "    ckpt = torch.load(file, map_location=\"cpu\")\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/utils/patches.py\", line 115, in torch_load\n",
            "    return _torch_load(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1425, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 751, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 732, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'runs/train/your_soccer_pitch_pretrained/weights/best.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keypoints Only"
      ],
      "metadata": {
        "id": "glh8ur3_nkgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 1: keypointâ€only head training\n",
        "!yolo task=pose mode=train \\\n",
        "    model=/content/drive/MyDrive/TestTesi/video/football-pitch-detection.pt \\\n",
        "    data={dataset.location}/data.yaml \\\n",
        "    hyp={dataset.location}/hyp_pose_keypoint_only.yaml \\\n",
        "    batch=8 \\\n",
        "    epochs=30 \\\n",
        "    imgsz=640 \\\n",
        "    lr0=1e-4 \\\n",
        "    freeze=backbone,detect \\\n",
        "    plots=True \\\n",
        "    patience=5"
      ],
      "metadata": {
        "id": "GgouEEvGnkBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 2: unfreeze a bit more of the head if needed\n",
        "!yolo task=pose mode=train \\\n",
        "    model=runs/train/pose/weights/best.pt \\\n",
        "    data={dataset.location}/data.yaml \\\n",
        "    hyp={dataset.location}/hyp_pose_keypoint_only.yaml \\\n",
        "    batch=8 \\\n",
        "    epochs=70 \\\n",
        "    imgsz=640 \\\n",
        "    lr0=5e-5 \\\n",
        "    freeze=backbone,model.24,model.23 \\\n",
        "    plots=True \\\n",
        "    patience=5"
      ],
      "metadata": {
        "id": "Y_INKd67np3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D2YkphuiaE7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54c0771-a0b8-4cb9-f09c-8f7c4d977be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x-pose.pt to 'yolov8x-pose.pt'...\n",
            "100% 133M/133M [00:05<00:00, 27.0MB/s]\n",
            "Ultralytics 8.3.130 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CPU (AMD EPYC 7B12)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/datasets/football-field-detection-1/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8x-pose.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/pose/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=pose, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 3.73MB/s]\n",
            "Overriding model.yaml kpt_shape=[17, 3] with kpt_shape=[32, 3]\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1  10379251  ultralytics.nn.modules.head.Pose             [1, [32, 3], [320, 640, 640]] \n",
            "YOLOv8x-pose summary: 224 layers, 69,813,891 parameters, 69,813,875 gradients, 265.4 GFLOPs\n",
            "\n",
            "Transferred 601/637 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1613.2Â±547.7 MB/s, size: 46.3 KB)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/football-field-detection-1/train/labels... 32 images, 0 backgrounds, 0 corrupt: 100% 32/32 [00:00<00:00, 306.00it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/football-field-detection-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1118.4Â±628.4 MB/s, size: 45.1 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/football-field-detection-1/valid/labels... 2 images, 0 backgrounds, 0 corrupt: 100% 2/2 [00:00<00:00, 692.30it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/football-field-detection-1/valid/labels.cache\n",
            "Plotting labels to runs/pose/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 103 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/pose/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100         0G      2.196      11.84     0.7022      5.705      2.777         16        640: 100% 2/2 [01:59<00:00, 59.92s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.75s/it]\n",
            "                   all          2          2      0.288      0.432      0.497      0.263          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/2 [00:54<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/__init__.py\", line 981, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 793, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\", line 212, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\", line 395, in _do_train\n",
            "    self.scaler.scale(self.loss).backward()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=pose mode=train model=yolov8x-pose.pt data={dataset.location}/data.yaml batch=8 epochs=150 imgsz=640 mosaic=0.0 patience = 8 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2YzgYX7hj2BT",
        "outputId": "6a0fae9a-6f5d-43d4-9f9d-f2d20c92abb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {HOME}/runs/pose/train/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrXM_8fwtobC",
        "outputId": "7af94048-83ee-4433-ff15-6fd6622da105"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args.yaml\t\tlabels.jpg   train_batch0.jpg  weights\n",
            "labels_correlogram.jpg\tresults.csv  train_batch1.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/pose/train/results.png', width=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "1-W8xUbVtpcl",
        "outputId": "092755c2-e5f4-485d-fede-7c9f863b7a54"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/runs/pose/train/results.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e0af254eab89>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{HOME}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{HOME}/runs/pose/train/results.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/runs/pose/train/results.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/pose/train/val_batch0_pred.jpg', width=600)"
      ],
      "metadata": {
        "id": "c-DVRY_Ftt__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate custom model"
      ],
      "metadata": {
        "id": "8tZNP_dhuMSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=pose mode=val model={HOME}/runs/pose/train/weights/best.pt data={dataset.location}/data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IREDjkfuEBj",
        "outputId": "0f83cf96-c640-4e62-c423-687d13c0b25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Ultralytics YOLOv8.2.63 ğŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8x-pose summary (fused): 287 layers, 69,784,275 parameters, 0 gradients, 264.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/football-field-detection-12/valid/labels.cache... 30 images, 0 backgrounds, 0 corrupt: 100% 30/30 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 2/2 [00:02<00:00,  1.42s/it]\n",
            "                   all         30         30      0.998          1      0.995      0.966      0.965      0.967       0.97      0.471\n",
            "Speed: 0.1ms preprocess, 36.7ms inference, 0.0ms loss, 24.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/pose/val\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy model on Roboflow"
      ],
      "metadata": {
        "id": "RTKy34iWucM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project.version(dataset.version).deploy(model_type=\"yolov8-pose\", model_path=f\"{HOME}/runs/pose/train/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZjsAmq4uR4b",
        "outputId": "77f314a3-7c84-4d8e-f1be-7613635e92b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependency ultralytics==8.0.196 is required but found version=8.2.63, to fix: `pip install ultralytics==8.0.196`\n",
            "Would you like to continue with the wrong version of ultralytics? y/n: y\n",
            "View the status of your deployment at: https://app.roboflow.com/roboflow-jvuqo/football-field-detection-f07vi/12\n",
            "Share your model with the world at: https://universe.roboflow.com/roboflow-jvuqo/football-field-detection-f07vi/model/12\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}